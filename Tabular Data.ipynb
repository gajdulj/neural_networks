{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Data\n",
    "\n",
    "Tabular data is the data that you most often see. It is data that you can cleanly write in a table. It has a set number of rows and columns, and for our example below, all the data is numeric.\n",
    "\n",
    "This is the one type of data that we will go over that is not necessarily suited to neural networks. Because it is so simple and so well studied, traditional ML can do quite well on it. \n",
    "\n",
    "That being said it makes a nice springboard to begin the rest of the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this data we will be using sklearn `make_classification`. This will generate a dummy classification dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = make_classification(n_samples=10_000, n_features=20, n_classes=2)\n",
    "X_syn, y_syn = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have two classes, this is binary classification, so predicting either 0 or a 1 based off of these 20 features.\n",
    "\n",
    "So now that we have the data we can just throw it into a NN right? \n",
    "\n",
    "Well not quite yet. Because a NN is basically a linear ML alg, we first need to scale all the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('titanic_train.csv')\n",
    "df.drop(['Name'], axis=1,inplace=True)\n",
    "df.drop(['Ticket'], axis=1,inplace=True)\n",
    "df.drop(['PassengerId'], axis=1,inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check n/a\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)\n",
    "df['Cabin'].fillna('cabin_unkown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes([np.number]).columns\n",
    "cat_cols = list(set(df.columns)-set(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute n/a Age\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "knn_predictions = imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "age_pos = list(df.columns).index('Age')\n",
    "# substract 1 from age col position, 0 is index.\n",
    "df['Age'] = knn_predictions[:,age_pos-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cabin', 'Sex', 'Embarked']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin_A10</th>\n",
       "      <th>Cabin_A14</th>\n",
       "      <th>Cabin_A16</th>\n",
       "      <th>Cabin_A19</th>\n",
       "      <th>Cabin_A20</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_F38</th>\n",
       "      <th>Cabin_F4</th>\n",
       "      <th>Cabin_G6</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_cabin_unkown</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Cabin_A10  Cabin_A14  Cabin_A16  \\\n",
       "0       3  22.0      1      0   7.2500          0          0          0   \n",
       "1       1  38.0      1      0  71.2833          0          0          0   \n",
       "2       3  26.0      0      0   7.9250          0          0          0   \n",
       "3       1  35.0      1      0  53.1000          0          0          0   \n",
       "4       3  35.0      0      0   8.0500          0          0          0   \n",
       "\n",
       "   Cabin_A19  Cabin_A20  ...  Cabin_F38  Cabin_F4  Cabin_G6  Cabin_T  \\\n",
       "0          0          0  ...          0         0         0        0   \n",
       "1          0          0  ...          0         0         0        0   \n",
       "2          0          0  ...          0         0         0        0   \n",
       "3          0          0  ...          0         0         0        0   \n",
       "4          0          0  ...          0         0         0        0   \n",
       "\n",
       "   Cabin_cabin_unkown  Sex_female  Sex_male  Embarked_C  Embarked_Q  \\\n",
       "0                   1           0         1           0           0   \n",
       "1                   0           1         0           1           0   \n",
       "2                   1           1         0           0           0   \n",
       "3                   0           1         0           0           0   \n",
       "4                   1           0         1           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891,), (891, 158))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.7659574468085106\n",
      "Accuracy score: 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, preds)\n",
    "acc = accuracy_score(y_test, preds.round())\n",
    "print(f\"f1 score:\",f1)\n",
    "print(f\"Accuracy score:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "standardized_x = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now we can just throw it into a NN :) \n",
    "\n",
    "Yup for this data there is not too much else to it but to build the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# dropout probability\n",
    "p = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be using keras to build our NN. Because this is tabular data we can follow a fairly simple structure of a NN:\n",
    "\n",
    "1. Standardize/Normalize\n",
    "2. (Optional) Regularize/Dropout\n",
    "3. Apply a Dense Layer\n",
    "\n",
    "Let me talk about the first and the last.\n",
    "\n",
    "In LR, coefficients will create issues, taht;s why we standardise.\n",
    "\n",
    "Standardizing is important because of the way that NNs train by using gradient descent. If a particular layer's input is too big, then the gradients might be massive and the training process goes out of wack. \n",
    "Standardisation is a monotonic function.\n",
    "In mathematics, a monotonic function is a function between ordered sets that preserves or reverses the given order.\n",
    "\n",
    "The dense layer is the core of the NN and applies a non-linear transformation to the inputs allowing the NN to represent any non-linear function - or something like that. Regardless without that you couldn't learn.\n",
    "\n",
    "Dropout is a simple way of regularizing NNs. The reason I put this as optional, is that there is some debate on whether you need dropout in addition to batch normalization.\n",
    "\n",
    "Ultimately you can experiment with the amt of dropout you need in your network, and if it's none, so be it.\n",
    "\n",
    "---\n",
    "\n",
    "So all that being said below is our first NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((158,), name='numeric_inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dropout(p)(inputs)\n",
    "x = tf.keras.layers.Dense(30, activation='relu')(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(30, activation='relu')(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "out = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are probably a couple of questions as to the above:\n",
    "\n",
    "* Why so many layers?\n",
    "* Why so many neurons in each layer\n",
    "\n",
    "Well a good rule of thumb is that your NN can have as many params as the number of data points that you have, and the above NN has half as many, so we could probably increase the number of parameters. \n",
    "\n",
    "As for the width vs the depth of the network, well there has been a ton of results on either side of the aisle and honeslty I'm not sure what to tell you other than experimentation.\n",
    "\n",
    "Some things you might want to keep in mind are:\n",
    "\n",
    "* Skip connections seem to be pretty cool\n",
    "* Alternating small and large layers might be a thing too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "numeric_inputs (InputLayer)  [(None, 158)]             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 158)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                4770      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 10,431\n",
      "Trainable params: 10,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final amendment to our data, I always like to use keras's `fit_generator` function, so I will often make a generator to feed data to the NN instead of using the default fit funtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bootstrap_sample_generator(batch_size):\n",
    "    while True:\n",
    "        batch_idx = np.random.choice(\n",
    "            standardized_x.shape[0], batch_size)\n",
    "        yield ({'numeric_inputs': standardized_x[batch_idx]}, \n",
    "               {'output': y[batch_idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.4492 - accuracy: 0.8108\n",
      "Epoch 2/10\n",
      "156/156 [==============================] - 1s 4ms/step - loss: 0.3355 - accuracy: 0.8655\n",
      "Epoch 3/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8718\n",
      "Epoch 4/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.3120 - accuracy: 0.8728\n",
      "Epoch 5/10\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8777\n",
      "Epoch 6/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.3031 - accuracy: 0.8810\n",
      "Epoch 7/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.8712\n",
      "Epoch 8/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.2949 - accuracy: 0.8830\n",
      "Epoch 9/10\n",
      "156/156 [==============================] - 1s 3ms/step - loss: 0.2968 - accuracy: 0.8813\n",
      "Epoch 10/10\n",
      "156/156 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd30534fa10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "model.fit_generator(\n",
    "    bootstrap_sample_generator(batch_size),\n",
    "    steps_per_epoch=10_000 // batch_size,\n",
    "    epochs=10,\n",
    "    max_queue_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.6567164179104478\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, pred.round())\n",
    "\n",
    "print(f\"f1 score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7430167597765364"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_elements(array):\n",
    "    (unique, counts) = np.unique(array.round(), return_counts=True)\n",
    "    frequencies = np.asarray((unique, counts)).T\n",
    "    return frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 140.],\n",
       "       [  1.,  39.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_elements(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 105],\n",
       "       [  1,  74]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_elements(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
